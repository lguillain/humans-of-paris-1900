{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haeeun\\Anaconda3\\lib\\site-packages\\tqdm\\autonotebook.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from fdh_gallica import Periodical, Search, Document\n",
    "from fdh_gallica.parallel_process import iiif_urls_for_documents\n",
    "from tqdm.autonotebook import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import itertools\n",
    "from itertools import chain\n",
    "from itertools import compress\n",
    "import re\n",
    "import wikipedia\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all images with relevant query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch BnF description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_names(x):\n",
    "    names_order = {1:[0],2:[1,0], 3:[2,0,1], 4:[3,0,1,2], 5:[4,0,1,2,3]}\n",
    "    s = x.split(',')\n",
    "    m = names_order[len(s)]\n",
    "    return ' '.join([y.strip() for x,y in sorted(zip(m,s))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = pd.read_pickle('data/id_name.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = names_df.rename(columns={'name':'raw_name'})\n",
    "names_df['name'] = names_df.raw_name.apply(lambda x: x.split('(')[0].strip())\n",
    "names_df['ordered_name'] = names_df.name.apply(reorder_names)\n",
    "names_df['sup'] =  names_df.raw_name.apply(lambda x: str(re.findall('\\(\\S+\\)',x)).strip(\"['']\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparql_str() :\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparql_uri(x, option='name'):\n",
    "    if option == 'name':\n",
    "        sparql_str.__doc__ = 'PREFIX foaf: <http://xmlns.com/foaf/0.1/>    SELECT ?pers     WHERE {    ?pers foaf:name \"%s\".    }    LIMIT 200' % (x)\n",
    "    elif option == 'familyName':        \n",
    "        sparql_str.__doc__ = 'PREFIX foaf: <http://xmlns.com/foaf/0.1/>    SELECT ?pers     WHERE {    ?pers foaf:familyName \"%s\".    }    LIMIT 200' % (x)        \n",
    "    elif option == 'givenName':\n",
    "        pass\n",
    "        \n",
    "    sparql = SPARQLWrapper(\"http://data.bnf.fr/sparql\")\n",
    "    sparql.setQuery(sparql_str.__doc__)\n",
    "    sparql.setReturnFormat(XML)\n",
    "    results = sparql.query().convert()\n",
    "    xml_ = results.toxml()\n",
    "    return list(map(lambda x: x[5:-6], re.findall(\"<uri>\\S*</uri>\", xml_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bnf_description(links):\n",
    "    result = {}\n",
    "\n",
    "    for link in links:\n",
    "        try:\n",
    "            page = requests.get(link)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            try:\n",
    "                bnf_text = soup.find(\"div\", {\"itemprop\": \"description\"}).get_text()\n",
    "            except:\n",
    "                bnf_text = ''\n",
    "            \n",
    "            bnf_title = soup.find(\"title\").get_text()\n",
    "            result[bnf_title] = (bnf_text, link)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637a400a92044813b0ba98f2cf441a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1963), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bnf_reset = False\n",
    "\n",
    "if bnf_reset:\n",
    "    \n",
    "    bnf_namelist = names_df.ordered_name#[0:60]\n",
    "    bnf_name_error = []\n",
    "    bnf_not_found = []\n",
    "    bnf_link = {}\n",
    "    \n",
    "    for i in tqdm(bnf_namelist):\n",
    "        l = i.split()\n",
    "        try:\n",
    "            s = sparql_uri(i)\n",
    "            \n",
    "            if s == []:\n",
    "                #try by familyname\n",
    "                s = sparql_uri(l[0], option='familyName')\n",
    "                \n",
    "                if s == []:\n",
    "                    s = sparql_uri(l[-1], option='familyName')\n",
    "                    \n",
    "                    if s == []:\n",
    "                        s = sparql_uri(i, option='familyName')\n",
    "                        \n",
    "                        if s == []:\n",
    "                            bnf_not_found3.append(i)\n",
    "                        else:\n",
    "                            pass\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "                      \n",
    "            bnf_link[i] = [s]\n",
    "        except:\n",
    "            bnf_name_error.append(i)\n",
    "            \n",
    "    with open('bnf_link.json', 'w') as fp:\n",
    "        json.dump(bnf_link, fp)\n",
    "        \n",
    "    bnf_df_ = pd.DataFrame.from_dict(bnf_link, orient='index', columns=['links'])\n",
    "    bnf_df_['bnf'] = bnf_df_.links.apply(get_bnf_description)\n",
    "    bnf_df_ = bnf_df_.reset_index().rename(columns={'index':'ordered_name'})\n",
    "    bnf_df_.to_pickle('data/bnf_text_raw.pkl')\n",
    "# takes about 20 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def handle_year(years):\n",
    "    try:\n",
    "        byear = years[0]\n",
    "        dyear = years[1]\n",
    "\n",
    "        try:\n",
    "            byear =  int(byear)\n",
    "        except:\n",
    "            byear =  1855\n",
    "\n",
    "        try:\n",
    "            dyear =  int(dyear)\n",
    "        except:\n",
    "            dyear =  1910\n",
    "        return  min(1910, dyear) - max(1855, byear)\n",
    "\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "def bnf_match(keys):\n",
    "    activity = range(1855, 1910)\n",
    "    \n",
    "    \n",
    "#    years = list(map(lambda x: re.findall('1[.89].+-1[.89].+',x),keys))\n",
    "    years = list(map(lambda x: str(re.findall('1[89].+-1[89].+',x)).strip(\"['()']\"), keys))\n",
    "\n",
    "    years_list = list(map(lambda x: handle_year(x.split('-')),years))\n",
    "    \n",
    "    \n",
    "    \n",
    "#    keys_new = list(compress(keys, map(lambda x: x != '',years)))\n",
    "    \n",
    "        \n",
    "    try :\n",
    "        return keys[np.argmax(years_list)]\n",
    "    except:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/bnf_name_error.json', 'w') as fp:\n",
    "    json.dump(bnf_name_error, fp)\n",
    "with open('data/bnf_not_found.json', 'w') as fp:\n",
    "    json.dump(bnf_not_found, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bnf_link.json','r') as fp:\n",
    "    bnf_link =  json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_df_ = pd.read_pickle('data/bnf_text_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_df_merge = pd.merge(bnf_df_, names_df[['raw_name','ordered_name','sup']], on='ordered_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_df_merge['names'] = bnf_df_merge.bnf.apply(lambda x: list(x.keys()))\n",
    "bnf_df_merge['title'] = bnf_df_merge.apply(lambda x:str(x.ordered_name + ' ' + x.sup).strip(), axis=1)\n",
    "bnf_df_merge['key_title'] = bnf_df_merge.apply(lambda x: list(compress(x.names, list(map(lambda y: x.title in y, x.names)))), axis=1)\n",
    "bnf_df_merge['key_name'] = bnf_df_merge.apply(lambda x: list(compress(x.names, list(map(lambda y: x.ordered_name in y, x.names)))), axis=1)\n",
    "bnf_df_merge['key_sup'] = bnf_df_merge.apply(lambda x: list(compress(x.names, list(map(lambda y: x.sup in y, x.names)))), axis=1)\n",
    "bnf_df_merge['key'] = bnf_df_merge.apply(lambda x: list(set.intersection(set(x.key_title), set(x.key_name), set(x.key_sup))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_df_merge['key_match'] = bnf_df_merge.key.apply(bnf_match)#.apply(lambda x: len(x)).value_counts(ascending=False)\n",
    "bnf_df_merge['description'] = bnf_df_merge.dropna(axis=0).apply(lambda x: x.bnf[x.key_match],axis=1)\n",
    "#bnf_df_merge[['ordered_name','description']].to_pickle('data/bnf_description.pkl')#.description.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_summary = bnf_df_merge[['raw_name','description']]\n",
    "bnf_summary['bnf_note'] = bnf_df_merge.description.apply(lambda x: x[0])\n",
    "bnf_summary['bnf_link'] = bnf_df_merge.description.apply(lambda x: x[1])\n",
    "#bnf_summary.to_pickle('data/bnf_summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Humans of Paris",
   "language": "python",
   "name": "humans-of-paris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
